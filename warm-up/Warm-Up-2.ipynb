{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pick a subreddit. What user wrote the most comments in January of 2012? What was the userâ€™s top three most-upvoted comments? Filter out bots or other types of automated posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "subReddit = 'AskReddit'\n",
    "author = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql.functions import from_json, col\n",
    "conf = SparkConf().setAppName('FirstSpark2').setMaster('Spark')\n",
    "sc = SparkContext.getOrCreate()\n",
    "\n",
    "from pyspark.sql import SQLContext\n",
    "sqlContext = SQLContext(sc)\n",
    "df = sqlContext.read.json(\"hdfs://orion11:20001/sample_sampled_reddit/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtering data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.sql.dataframe.DataFrame'>\n",
      "27303462\n",
      "+--------+--------------+--------------+----------------------+-----------------+--------------------+---------+----------------+-------+-----------+-------------+-----+------+------+-------+---------+-----------+----+---------+--------------+-------+------------+-----+-----+------------+--------+---------------+------------+---+------------+\n",
      "|archived|        author|author_cakeday|author_flair_css_class|author_flair_text|                body|body_html|controversiality|created|created_utc|distinguished|downs|edited|gilded|     id|  link_id|mod_reports|name|parent_id|removal_reason|replies|retrieved_on|saved|score|score_hidden|stickied|      subreddit|subreddit_id|ups|user_reports|\n",
      "+--------+--------------+--------------+----------------------+-----------------+--------------------+---------+----------------+-------+-----------+-------------+-----+------+------+-------+---------+-----------+----+---------+--------------+-------+------------+-----+-----+------------+--------+---------------+------------+---+------------+\n",
      "|    null|distanceformed|          null|                 green|           7/7/17|I need hash tag h...|     null|               0|   null| 1474469708|         null| null| false|     0|d7w2ag1|t3_53tgt2|       null|null|t3_53tgt2|          null|   null|  1475908052| null|    6|        null|   false|weddingplanning|    t5_2rv3t|  6|        null|\n",
      "+--------+--------------+--------------+----------------------+-----------------+--------------------+---------+----------------+-------+-----------+-------------+-----+------+------+-------+---------+-----------+----+---------+--------------+-------+------------+-----+-----+------------+--------+---------------+------------+---+------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2 = df.filter(\n",
    "~(df.body.like('[deleted]'))\n",
    "    & ~(df.body.isNull())\n",
    "    & ~(df.author.like('[deleted]'))\n",
    "    & ~(df.author.like('AutoModerator')) \n",
    "    & ~(df.author.rlike(\"[bB][oO][tT]\"))\n",
    "\n",
    ")\n",
    "\n",
    "print(type(df2))\n",
    "print(df2.count())\n",
    "df2.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting the name of subreddits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.sql.dataframe.DataFrame'>\n",
      "88429\n",
      "+---------------+-------+\n",
      "|      subreddit|  count|\n",
      "+---------------+-------+\n",
      "|      AskReddit|2443278|\n",
      "|          funny| 545756|\n",
      "|           pics| 508294|\n",
      "|       politics| 441766|\n",
      "|leagueoflegends| 437114|\n",
      "|         gaming| 353938|\n",
      "|            WTF| 305215|\n",
      "|            nfl| 298155|\n",
      "|  AdviceAnimals| 290879|\n",
      "|      worldnews| 289444|\n",
      "|         videos| 282651|\n",
      "|  todayilearned| 255729|\n",
      "|            nba| 243260|\n",
      "|         soccer| 198731|\n",
      "|           news| 197988|\n",
      "|         movies| 177056|\n",
      "|           IAmA| 175689|\n",
      "|          DotA2| 174396|\n",
      "|   pcmasterrace| 166760|\n",
      "|         hockey| 166410|\n",
      "+---------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3 = df2.groupBy(df2.subreddit)\n",
    "df3 = df3.count()\n",
    "\n",
    "print(type(df3))\n",
    "print(df3.count())\n",
    "df3.orderBy('count', ascending=False).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Picking subreddit - gaming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtering the data to have comments for subreddit - \"gaming\", in the month - January and year - 2012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.sql.dataframe.DataFrame'>\n",
      "16938\n",
      "+--------+------------+--------------+----------------------+-----------------+--------------------+---------+----------------+-------+-----------+-------------+-----+------+------+-------+--------+-----------+----------+---------+--------------+-------+------------+-----+-----+------------+--------+---------+------------+---+------------+\n",
      "|archived|      author|author_cakeday|author_flair_css_class|author_flair_text|                body|body_html|controversiality|created|created_utc|distinguished|downs|edited|gilded|     id| link_id|mod_reports|      name|parent_id|removal_reason|replies|retrieved_on|saved|score|score_hidden|stickied|subreddit|subreddit_id|ups|user_reports|\n",
      "+--------+------------+--------------+----------------------+-----------------+--------------------+---------+----------------+-------+-----------+-------------+-----+------+------+-------+--------+-----------+----------+---------+--------------+-------+------------+-----+-----+------------+--------+---------+------------+---+------------+\n",
      "|    true|theoderic123|          null|                  null|             null|It's a lot cheape...|     null|               0|   null| 1325876240|         null|    0| false|     0|c3ekpje|t3_o5iup|       null|t1_c3ekpje| t3_o5iup|          null|   null|  1428134715| null|    2|       false|    null|AskReddit|    t5_2qh1i|  2|        null|\n",
      "+--------+------------+--------------+----------------------+-----------------+--------------------+---------+----------------+-------+-----------+-------------+-----+------+------+-------+--------+-----------+----------+---------+--------------+-------+------------+-----+-----+------------+--------+---------+------------+---+------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import year, month, dayofmonth, from_unixtime\n",
    "from pyspark.sql.types import DateType\n",
    "\n",
    "df4 = df2.where(df2.subreddit.like(subReddit)).where(year(from_unixtime(\"created_utc\").cast(DateType()))==2012).where(month(from_unixtime(\"created_utc\").cast(DateType()))== 1)\n",
    "\n",
    "print(type(df4))\n",
    "print(df4.count())\n",
    "df4.show(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For the above subreddit fetching the author who has made the most number of comments in January 2012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----+\n",
      "|         author|count|\n",
      "+---------------+-----+\n",
      "|NinjaDiscoJesus|   35|\n",
      "|       iam4real|   24|\n",
      "|andrewsmith1986|   23|\n",
      "|        jhudsui|   22|\n",
      "|         Lots42|   21|\n",
      "+---------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "groupedByAuthor = df4.groupBy(\"author\").count().orderBy('count', ascending=False)\n",
    "groupedByAuthor.show(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecting top author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "NinjaDiscoJesus\n"
     ]
    }
   ],
   "source": [
    "author = groupedByAuthor.select('author').head(1)\n",
    "author =(author[0]).author\n",
    "print(type(author))\n",
    "print(author)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### odering author comments by ups (decending)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+---------------+----------------------------------------------------------------------------------------------------------+---+\n",
      "|id     |subreddit|author         |body                                                                                                      |ups|\n",
      "+-------+---------+---------------+----------------------------------------------------------------------------------------------------------+---+\n",
      "|c3mf9mb|AskReddit|NinjaDiscoJesus|I dunno... shouldn't both be kept quiet until the verdict.. then only the victim should have protection.. |57 |\n",
      "|c3g3q8s|AskReddit|NinjaDiscoJesus|You don't drink anyway near an amount that would be considered 'a lot'                                    |32 |\n",
      "|c3i87tn|AskReddit|NinjaDiscoJesus|nope.. neither did the mayans I believe                                                                   |8  |\n",
      "+-------+---------+---------------+----------------------------------------------------------------------------------------------------------+---+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df5 = df4.where(df4.subreddit.like(subReddit)).where(df4.author == author).orderBy('ups', ascending=False)\n",
    "df5.select(df5.id, df5.subreddit, df5.author, df5.body, df5.ups).show(3, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
