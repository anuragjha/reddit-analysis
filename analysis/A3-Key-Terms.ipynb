{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Terms: \n",
    "calculate the TF-IDF for a given subreddit.\n",
    "\n",
    "Produce a Tag Cloud of the terms (note: this doesnâ€™t have to be integrated into your code; simply including the image is enough)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddit='newzealand'\n",
    "# word = \n",
    "concatenatedString = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql.functions import from_json, col\n",
    "conf = SparkConf().setAppName('FirstSpark2').setMaster('Spark')\n",
    "sc = SparkContext.getOrCreate()\n",
    "\n",
    "from pyspark.sql import SQLContext\n",
    "sqlContext = SQLContext(sc)\n",
    "df = sqlContext.read.json(\"hdfs://orion11:20001/sample_sampled_reddit/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtering data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.sql.dataframe.DataFrame'>\n",
      "27303462\n",
      "+--------+--------------+--------------+----------------------+-----------------+--------------------+---------+----------------+-------+-----------+-------------+-----+------+------+-------+---------+-----------+----+---------+--------------+-------+------------+-----+-----+------------+--------+---------------+------------+---+------------+\n",
      "|archived|        author|author_cakeday|author_flair_css_class|author_flair_text|                body|body_html|controversiality|created|created_utc|distinguished|downs|edited|gilded|     id|  link_id|mod_reports|name|parent_id|removal_reason|replies|retrieved_on|saved|score|score_hidden|stickied|      subreddit|subreddit_id|ups|user_reports|\n",
      "+--------+--------------+--------------+----------------------+-----------------+--------------------+---------+----------------+-------+-----------+-------------+-----+------+------+-------+---------+-----------+----+---------+--------------+-------+------------+-----+-----+------------+--------+---------------+------------+---+------------+\n",
      "|    null|distanceformed|          null|                 green|           7/7/17|I need hash tag h...|     null|               0|   null| 1474469708|         null| null| false|     0|d7w2ag1|t3_53tgt2|       null|null|t3_53tgt2|          null|   null|  1475908052| null|    6|        null|   false|weddingplanning|    t5_2rv3t|  6|        null|\n",
      "+--------+--------------+--------------+----------------------+-----------------+--------------------+---------+----------------+-------+-----------+-------------+-----+------+------+-------+---------+-----------+----+---------+--------------+-------+------------+-----+-----+------------+--------+---------------+------------+---+------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2 = df.filter(\n",
    "~(df.body.like('[deleted]'))\n",
    "    & ~(df.body.isNull())\n",
    "    & ~(df.author.like('[deleted]'))\n",
    "    & ~(df.author.like('AutoModerator')) \n",
    "    & ~(df.author.rlike(\"[bB][oO][tT]\"))\n",
    "\n",
    ")\n",
    "\n",
    "print(type(df2))\n",
    "print(df2.count())\n",
    "df2.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88429"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subCount = df2.select(\"subreddit\").distinct().count()\n",
    "subCount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting Query for chosen subreddit :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subreddit='apple'\n",
    "query_df = df2#.filter(df2.subreddit==subreddit)\n",
    "\n",
    "# print(type(query_df))\n",
    "# print(query_df.count())\n",
    "# query_df.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting words in body of filtered subreddit rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.sql.dataframe.DataFrame'>\n",
      "903761043\n",
      "+---------------+--------+\n",
      "|      subreddit|    word|\n",
      "+---------------+--------+\n",
      "|weddingplanning|       i|\n",
      "|weddingplanning|    need|\n",
      "|weddingplanning|    hash|\n",
      "|weddingplanning|     tag|\n",
      "|weddingplanning|    help|\n",
      "|weddingplanning|      my|\n",
      "|weddingplanning|    last|\n",
      "|weddingplanning|    name|\n",
      "|weddingplanning|      is|\n",
      "|weddingplanning|  sitter|\n",
      "|weddingplanning|     and|\n",
      "|weddingplanning|     his|\n",
      "|weddingplanning|      is|\n",
      "|weddingplanning|  ritter|\n",
      "|weddingplanning|       i|\n",
      "|weddingplanning|      ll|\n",
      "|weddingplanning|      be|\n",
      "|weddingplanning|changing|\n",
      "|weddingplanning|      my|\n",
      "|weddingplanning|    last|\n",
      "+---------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as func\n",
    "import re\n",
    "from pyspark.sql.types import StringType, DoubleType, IntegerType\n",
    "\n",
    "def preProcessBody(text):\n",
    "    # lowercase\n",
    "    text=text.lower()\n",
    "    text=re.sub(\"[^A-Za-z]+\",\" \",text)\n",
    "    return text.strip()\n",
    "\n",
    "# print(preProcessBody(\"who_is_there\"))\n",
    "\n",
    "preProcessBodyUdf = func.udf(preProcessBody, StringType())\n",
    "\n",
    "commentsTokensDF = (query_df\n",
    "                    .select(\n",
    "                        \"subreddit\",\n",
    "                        func.explode(func.split(preProcessBodyUdf(query_df.body), \"\\s+\")).alias(\"word\")\n",
    "                    )\n",
    "                   )\n",
    "\n",
    "#query_df.unpersist()\n",
    "# commentsTokensDF.cache()\n",
    "\n",
    "print(type(commentsTokensDF))\n",
    "print(commentsTokensDF.count())\n",
    "commentsTokensDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home4/ajha6/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "433093657\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stopWords = stopwords.words()\n",
    "\n",
    "commentsTokensDF = commentsTokensDF.filter(commentsTokensDF.word.isin(*stopWords) == False)\n",
    "\n",
    "print(commentsTokensDF.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### calculating tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.sql.dataframe.DataFrame'>\n",
      "47460196\n",
      "+-------------------+-----------+----+\n",
      "|          subreddit|       word|  tf|\n",
      "+-------------------+-----------+----+\n",
      "|       windowsphone|        uwp|  95|\n",
      "|                rit|     campus| 148|\n",
      "|               pics|      rules|2098|\n",
      "|    leagueoflegends|       case|3473|\n",
      "|                wow|  sacrifice| 108|\n",
      "|                DnD|     better| 946|\n",
      "|              piano|    entered|   1|\n",
      "|      AdviceAnimals|transported|  10|\n",
      "|      AdviceAnimals|        ufo|   8|\n",
      "|         television|    content| 383|\n",
      "|                wow|       back|4536|\n",
      "|      SquaredCircle|      clash| 148|\n",
      "|            OkCupid|        tbh|  87|\n",
      "|            teenmom|       feel| 240|\n",
      "|            xboxone|         tv|1222|\n",
      "|    TwoXChromosomes|       cute| 405|\n",
      "|      todayilearned|        lol|2054|\n",
      "|PoliticalDiscussion|     reason|1303|\n",
      "|            Fitness|  guideline|  23|\n",
      "|     DestinyTheGame|        roi| 419|\n",
      "+-------------------+-----------+----+\n",
      "only showing top 20 rows\n",
      "\n",
      "CPU times: user 34.6 ms, sys: 16.3 ms, total: 50.9 ms\n",
      "Wall time: 1min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "wordTf = (commentsTokensDF.groupBy(\"subreddit\",\"word\")\n",
    "        .agg(func.count(\"subreddit\").alias(\"tf\")))\n",
    "# wordTf.cache()\n",
    "\n",
    "print(type(wordTf))\n",
    "print(wordTf.count())\n",
    "wordTf.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### calculating df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|  word|   df|\n",
      "+------+-----+\n",
      "|  like|33541|\n",
      "|   get|29643|\n",
      "| would|28875|\n",
      "|  http|27192|\n",
      "|  good|26544|\n",
      "| think|26339|\n",
      "|  know|25847|\n",
      "|  time|25223|\n",
      "|really|25154|\n",
      "|   www|24593|\n",
      "|   see|24042|\n",
      "|  well|23472|\n",
      "|people|23369|\n",
      "|  much|23176|\n",
      "|  make|22796|\n",
      "| could|22565|\n",
      "|thanks|22091|\n",
      "|    go|22046|\n",
      "| https|21941|\n",
      "| still|21590|\n",
      "+------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "CPU times: user 32.6 ms, sys: 15.7 ms, total: 48.2 ms\n",
      "Wall time: 52.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "wordDf = (commentsTokensDF.groupBy(\"word\")\n",
    "        .agg(func.countDistinct(\"subreddit\").alias(\"df\")))\n",
    "# commentsTokensDF.unpersist()\n",
    "# wordDf.cache()\n",
    "wordDf.orderBy(wordDf.df, ascending=False).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### calculating idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+------------------+\n",
      "|      word|   df|               idf|\n",
      "+----------+-----+------------------+\n",
      "|      earl|  677|4.8708192696293855|\n",
      "|commanders|  398| 5.401005140679917|\n",
      "|    brands| 1916|3.8314498145241362|\n",
      "|     yoshi|  341| 5.555155820507175|\n",
      "|    online|11389| 2.049475501128553|\n",
      "|  tripping| 1102| 4.384177538316278|\n",
      "|  nicotine|  564|5.0531408264233395|\n",
      "|      neet|  169| 6.254168120519519|\n",
      "|   tanques|    7| 9.310525015889946|\n",
      "|      hope|14654| 1.797429704424788|\n",
      "|  fiscally|  302| 5.676233752060412|\n",
      "| recognize| 3858| 3.131803196032162|\n",
      "| litterers|   17| 8.499594799673616|\n",
      "|    harder| 5942|  2.69999722220312|\n",
      "|     papeg|    1|10.696819377009836|\n",
      "| arguments| 2843|3.4369997666466494|\n",
      "|     still|21590| 1.409934717393867|\n",
      "| standards| 3488| 3.232596116383007|\n",
      "|       art| 6541|2.6039683494714514|\n",
      "| connected| 3791| 3.149317694194868|\n",
      "+----------+-----+------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "CPU times: user 17.8 ms, sys: 16.9 ms, total: 34.7 ms\n",
      "Wall time: 49.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import pyspark.sql.functions as func\n",
    "from pyspark.sql.types import StringType, DoubleType\n",
    "import string\n",
    "import re\n",
    "import math\n",
    "\n",
    "def calcIdf(docCount, df):\n",
    "    return math.log((float(docCount) + 1) / (float(df) + 1))\n",
    "#     return math.log((float(docCount) + 1))\n",
    "\n",
    "calcIdfUdf = func.udf(calcIdf, DoubleType())\n",
    "\n",
    "\n",
    "wordIdf = (wordDf\n",
    "           .withColumn(\"idf\", calcIdfUdf(func.lit(subCount), wordDf.df)))\n",
    "# wordDf.unpersist()\n",
    "# wordIdf.cache()\n",
    "wordIdf.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtering for a subreddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+---+\n",
      "| subreddit|          word| tf|\n",
      "+----------+--------------+---+\n",
      "|newzealand|        system|259|\n",
      "|newzealand|     countries|155|\n",
      "|newzealand|        double| 47|\n",
      "|newzealand|         happy|147|\n",
      "|newzealand|          boat| 32|\n",
      "|newzealand|      tailored|  3|\n",
      "|newzealand|      building|121|\n",
      "|newzealand|         march| 23|\n",
      "|newzealand|         texts| 17|\n",
      "|newzealand|sterilisations|  1|\n",
      "|newzealand|          jerk| 12|\n",
      "|newzealand|      curtains|  5|\n",
      "|newzealand|         share| 50|\n",
      "|newzealand|        motifs|  1|\n",
      "|newzealand|        degree| 84|\n",
      "|newzealand|          move|160|\n",
      "|newzealand|     dickinson|  1|\n",
      "|newzealand|  unreasonable| 11|\n",
      "|newzealand|     manhattan|  1|\n",
      "|newzealand|   trafficking|  4|\n",
      "+----------+--------------+---+\n",
      "only showing top 20 rows\n",
      "\n",
      "CPU times: user 11.8 ms, sys: 4.85 ms, total: 16.6 ms\n",
      "Wall time: 23.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "selectSub = subreddit\n",
    "selectSubTf = wordTf.filter(wordTf.subreddit.like(selectSub))\n",
    "\n",
    "# wordIdf.unpersist()\n",
    "\n",
    "selectSubTf.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating tdf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+----+-----+------------------+------------------+\n",
      "|      word| subreddit|  tf|   df|               idf|            tf_idf|\n",
      "+----------+----------+----+-----+------------------+------------------+\n",
      "|        nz|newzealand|1694| 1738|3.9289010432154976| 6655.558367207053|\n",
      "|    people|newzealand|2433|23369|1.3307581300368772| 3237.734530379722|\n",
      "|  auckland|newzealand| 515|  270|  5.78784773669008| 2980.741584395391|\n",
      "|        gt|newzealand|1548|19047| 1.535249169403082| 2376.565714235971|\n",
      "|   zealand|newzealand| 548| 1270| 4.242407286380327| 2324.839192936419|\n",
      "|     would|newzealand|2056|28875| 1.119200478310729| 2301.076183406859|\n",
      "|      like|newzealand|2323|33541|0.9694128936782076|2251.9461520144764|\n",
      "|       get|newzealand|1959|29643|1.0929515344985314| 2141.092056082623|\n",
      "|     think|newzealand|1568|26339|1.2111225822725087|1899.0402090032935|\n",
      "|     maori|newzealand| 280|  179|  6.19700970667957|1735.1627178702797|\n",
      "|       new|newzealand|1140|20515|1.4610062090606217|1665.5470783291087|\n",
      "|government|newzealand| 533| 4417| 2.996524173589718|1597.1473845233197|\n",
      "|      good|newzealand|1201|26544| 1.203369872552009|1445.2472169349628|\n",
      "|      time|newzealand|1150|25223| 1.254415356344884|1442.5776597966167|\n",
      "|  national|newzealand| 452| 3856| 3.132321599361553|1415.8093629114219|\n",
      "|      even|newzealand| 953|21314|  1.42280022837047|1355.9286176370579|\n",
      "|    really|newzealand|1067|25154|1.2571545946443619| 1341.383952485534|\n",
      "|     going|newzealand| 923|20772|1.4485572120350962|1337.0183067083938|\n",
      "|    labour|newzealand| 296| 1047|4.4353276926887935|1312.8569970358828|\n",
      "|      work|newzealand| 887|20144| 1.479255159944333|1312.0993268706234|\n",
      "+----------+----------+----+-----+------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "CPU times: user 61.7 ms, sys: 22.6 ms, total: 84.3 ms\n",
      "Wall time: 1min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "selectedSubTfIdf = (selectSubTf\n",
    "      .join(wordIdf, [\"word\"],how='left')\n",
    "      .withColumn(\"tf_idf\", wordTf.tf * wordIdf.idf))\n",
    "\n",
    "selectedSubTfIdf.sort(func.desc(\"tf_idf\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>tf_idf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nz</td>\n",
       "      <td>6655.558367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>people</td>\n",
       "      <td>3237.734530</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     word       tf_idf\n",
       "0      nz  6655.558367\n",
       "1  people  3237.734530"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fDist = selectedSubTfIdf.select('word', 'tf_idf').orderBy('tf_idf', ascending=False) #converting RDD to spark dataframe\n",
    "df_fDist.createOrReplaceTempView(\"myTable\") \n",
    "# df211 = spark.sql(\"SELECT _1 AS Keywords, _2 as Frequency from myTable limit 20\") #renaming columns \n",
    "pandD = df_fDist.toPandas() #converting spark dataframes to pandas dataframes\n",
    "\n",
    "pandD.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fDist.limit(500).write.csv('hdfs://orion11:20001/wordCloud4.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking word cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![wordCloud](https://drive.google.com/file/d/17TYbMWBAosbh1x8VJK_CskhlEJ3Tab80/view?usp=sharing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "link - https://drive.google.com/file/d/17TYbMWBAosbh1x8VJK_CskhlEJ3Tab80/view?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
